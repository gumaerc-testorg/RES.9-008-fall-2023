---
content_type: page
description: Seminar contents.
draft: false
title: Principles and Applications of Relational Inductive Biases in Deep Learning
uid: e8dff8ff-ae28-47e5-bac7-fdf4cd38d8c7
---
**Taught by:** *Kelsey Allen, MIT (April 11, 2019)*

**Video:** {{% resource_link "9f702a9c-021b-49aa-88a0-f43ae6727105" "Principles and Applications of Relational Inductive Biases in Deep Learning" %}}

**Description:** Common intuition posits that deep learning has succeeded because of its ability to assume very little structure in the data it receives, instead learning that structure from large numbers of training examples. However, recent work has attempted to bring structure back into deep learning, via a new set of models known as "graph networks." Graph networks allow for "relational inductive biases" to be introduced into learning, i.e. explicit reasoning about relationships between entities. In this talk, I will introduce graph networks and one application to a physical reasoning task where an agent and human participants were asked to glue together pairs of blocks to stabilize a tower. We will go through DeepMind's recently released graph networks library (implemented in TensorFlow) to see how to set up different graph models and train some simple models on some simple tasks.

**Speaker Bio:** Kelsey Allen is a PhD student working with Josh Tenenbaum on the problems of structured physical reasoning, planning, and learning from limited data.

**Additional Resources:** Computational tutorial references and videos can be found on our {{% resource_link "e0f17851-67a4-4bbd-86f4-994ad9391688" "Stellar site" %}}.
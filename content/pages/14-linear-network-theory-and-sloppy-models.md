---
content_type: page
description: Seminar contents.
draft: false
title: Linear Network Theory and Sloppy Models
uid: 7139c8a4-6d32-46d5-a908-565bc0202de6
---
**Taught by:** *Mark Goldman, UC Davis (November 21, 2016)*

**Description:** This tutorial describes how to apply linear network theory to the analysis and interpretation of neural data. It introduces the concept of “sloppy models” that capture a common problem in model-fitting, in which individual model parameters are poorly constrained by available data (i.e. have “poorly/sloppily constrained parameter values”). Simple methods are illustrated for describing which combination of parameters most affect a particular model fit. This material is relevant to problems in neuroscience involving the interpretation of multidimensional data from recurrently connected systems.

**Slides:**

- {{% resource_link "4d4c1f32-5af9-49d8-93a0-63151adf17de" "Linear Network Theory and Sloppy Models (PPT)" %}} (Mark Goldman’s lecture slides)
- {{% resource_link "9eb064a7-0a5d-4e42-8cfd-0df8babc9855" "Introduction to Linear Algebra (PPT)" %}} (Mark Goldman and Emily Mackevicius slides)

**Additional Resources:**

- {{% resource_link "980c0e36-9572-4a43-a094-31ffe59e6808" "Sloppy model problems" %}}
- {{% resource_link "4b86daf3-668f-47e1-9323-145752222b1e" "Linear network theory problems" %}}
- MATLAB code: {{% resource_link "8daa9881-105d-46d7-a3f0-66bf0017fe43" "Integration for a recurrently connected network of two neurons" %}}
- MATLAB code: {{% resource_link "fa1c2414-eb34-4417-8c15-ed4f14dff006" "Amplification for a recurrently connected network of two neurons" %}}